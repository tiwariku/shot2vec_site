{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shot2vec model notes\n",
    "This notebook summarizes the model development process for the shot2vec website. A predictive text approach is taken with the mapping:\n",
    "\n",
    "*All NHL games* $\\Leftrightarrow$ *corpus*\n",
    "\n",
    "*list of plays from an NHL game* $\\Leftrightarrow$ *document*\n",
    "\n",
    "*serialized representation of a play* $\\Leftrightarrow $ *word*\n",
    "\n",
    "The overall goal of the model is to predict a probability distribution for the next play given the current and previous plays in a given game. This may be done with a recurrent neural network whose input and output spaces are the set of possible plays, and whose output layer has softmax activation (i.e. represents a valid probability distribution).\n",
    "\n",
    "The initial representation of the plays (words) is categorical. \n",
    "Each distinct play (play type, location), corresponds to a distinct one-hot vector in a space whose dimension is the number of distinct plays in the corpus. \n",
    "This basis is readable from a human perspective, and can represent a probability distribution over the set of possible plays (the one-hot, i.e. the Kronoker-delta function, is simply on possible distribution). \n",
    "On the other hand, if the number of possible plays is large (e.g., if spatial information is included with resonable granularity), it may be difficult for a neural network to learn from a game (document) in this representation. \n",
    "The solution to this problem is to create a dense 'embedded' representation of the plays using a variational autoencoder.\n",
    "In the dense embedded basis, a neural network will have an easier time learning patterns from the games (documents).\n",
    "We use Gensim's Word2Vec encoding scheme to learn our embedded basis, and train our own softmax layer to decode back to the categorical basis.\n",
    "These layers are time-distributed, meaning they preform a change of basis on the play vectors which is independent of the time-step (i.e. position within the document).\n",
    "\n",
    "Within the embedded basis, we use a simple two-layer LSTM recurrent neural network. The output of this network is then transformed to the categorical basis using the softmax layer.\n",
    "\n",
    "We compare the performance of this model to a baseline model$-$a 1st order Markov model. Which makes predictions by sampling the emperical distribution of plays following the current play. We find an adjusted$^\\dagger$ **33% validation accuracy for our model**, compared with **19% accuracy for the baseline model**. \n",
    "\n",
    "\n",
    "$^\\dagger$To train the neural network, we had to pad all of the games to the same length with trailing placeholder plays. As a result, roughly 36% of the plays in the corpus are padding plays, which are ~trivially predicted by both the baseline and the RNN model, and are reflected in the validation accuracy reported by ```tensorflow.keras```. To calculate the adjusted accuracies, we remove these plays from the picture under the assumption that they are correctly predicted always by both the baseline and RNN models. This assumption is self-evidently true for the baseline Markov model, and appears to be justified for the RNN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the corpus and pad to constant sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will load the corpus in to memory (it's only ~150 MB). We will then pad all of the games to the same length so that we may use batch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import corpse_maker as cm\n",
    "import data_processing as dp\n",
    "import model_fns as mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 1min 31s, total: 3min 3s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "STRIP_FN = cm.strip_name_zone\n",
    "CORPUS = dp.get_corpus(2010, 2018, STRIP_FN)\n",
    "GAME_LEN = 500\n",
    "dp.pad_corpus(CORPUS, game_len=GAME_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-encoding using gensim's word2vec embedding\n",
    "\n",
    "We will construct the embedding matrix using gensim's word2vec algorithm. The softmax layer may also be trained using an autoencoder structure and the gensim-word2vec embedding matrix. These trained layers may then be used either as untrainable encoding and decoding layers between the initial basis and the embedded basis, or as initial weights for trainable layers with the same purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the embedding layer\n",
    "First we train the embedding layer. Gensim's Word2Vec package will return a model where ```wv = model.wv``` is a set of keyed vectors. The keys are the the play strings, sorted in descending order of count, with corresponding zero-origined indices. The values are the embedded representation of the given key (index).\n",
    "\n",
    "    \n",
    "```python\n",
    "wv.vocab[play].index\n",
    "``` \n",
    "is the index of ```play```\n",
    "\n",
    "```python \n",
    "wv.vocab[play].count\n",
    "``` \n",
    "is the number of times ```play``` appears in the corpus\n",
    "\n",
    "```python\n",
    "wv[play]\n",
    "```\n",
    "is the embedded vector representing ```play```\n",
    "\n",
    "```python\n",
    "wv.index2word[index]\n",
    "``` \n",
    "is the ```play``` associated with ```index```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 20\n",
    "CORPUS_NAME = f'zones_{EMBEDDING_DIM}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writes the embedding files\n",
    "dp.make_embedding(CORPUS_NAME, CORPUS, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from tensorflow.keras.utils import to_categorical as one_hot\n",
    "CORPUS_IND = np.load(f'{CORPUS_NAME}.npy')\n",
    "WV = KeyedVectors.load(f'{CORPUS_NAME}.wv')\n",
    "CATAGORICAL_DIM = WV.vectors.shape[0]\n",
    "CORPUS_ONE = one_hot(CORPUS_IND, len(WV.vectors))\n",
    "EMBEDDING_MATRIX = WV.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the softmax decoding layer\n",
    "With the embedding layer quickly calculated, we can train a softmax decoding layer. It's possible that this is unnecessary, and can be done in conjunction with the subsequent hidden layer training, but training one now will provide a sanity check that our embedded representation is minimally lossy, and that it is possible to decode to the original representation. We find a validation accuracy of **.9996** for this autoencoder using a embedding space of dimension 20, suggesting that the embedded representation faithfully encodes almost all of the information about each play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = dp.tvt_split(CORPUS_IND)\n",
    "y_train = one_hot(X_train, CATAGORICAL_DIM)\n",
    "y_valid = one_hot(X_valid, CATAGORICAL_DIM)\n",
    "y_test = one_hot(X_test, CATAGORICAL_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0814 16:31:54.762890 4652467648 deprecation.py:506] From /Users/tiwariku/environments/shot2vec/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 16:31:54.782175 4652467648 deprecation.py:506] From /Users/tiwariku/environments/shot2vec/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0814 16:31:55.039746 4652467648 deprecation.py:323] From /Users/tiwariku/environments/shot2vec/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6187 samples, validate on 2062 samples\n",
      "Epoch 1/50\n",
      "6187/6187 [==============================] - 5s 802us/sample - loss: 5.5352 - acc: 0.0783 - val_loss: 4.2657 - val_acc: 0.1321\n",
      "Epoch 2/50\n",
      "6187/6187 [==============================] - 5s 788us/sample - loss: 3.2135 - acc: 0.2200 - val_loss: 2.3193 - val_acc: 0.6054\n",
      "Epoch 3/50\n",
      "6187/6187 [==============================] - 5s 767us/sample - loss: 2.0224 - acc: 0.6086 - val_loss: 1.8272 - val_acc: 0.6074\n",
      "Epoch 4/50\n",
      "6187/6187 [==============================] - 5s 783us/sample - loss: 1.6936 - acc: 0.6125 - val_loss: 1.5760 - val_acc: 0.6338\n",
      "Epoch 5/50\n",
      "6187/6187 [==============================] - 5s 779us/sample - loss: 1.4742 - acc: 0.6392 - val_loss: 1.3842 - val_acc: 0.6394\n",
      "Epoch 6/50\n",
      "6187/6187 [==============================] - 5s 843us/sample - loss: 1.3051 - acc: 0.6738 - val_loss: 1.2378 - val_acc: 0.7389\n",
      "Epoch 7/50\n",
      "6187/6187 [==============================] - 5s 803us/sample - loss: 1.1782 - acc: 0.7649 - val_loss: 1.1269 - val_acc: 0.7847\n",
      "Epoch 8/50\n",
      "6187/6187 [==============================] - 5s 785us/sample - loss: 1.0783 - acc: 0.7984 - val_loss: 1.0365 - val_acc: 0.8175\n",
      "Epoch 9/50\n",
      "6187/6187 [==============================] - 5s 755us/sample - loss: 0.9956 - acc: 0.8181 - val_loss: 0.9605 - val_acc: 0.8237\n",
      "Epoch 10/50\n",
      "6187/6187 [==============================] - 5s 763us/sample - loss: 0.9254 - acc: 0.8238 - val_loss: 0.8955 - val_acc: 0.8237\n",
      "Epoch 11/50\n",
      "6187/6187 [==============================] - 5s 763us/sample - loss: 0.8650 - acc: 0.8241 - val_loss: 0.8391 - val_acc: 0.8262\n",
      "Epoch 12/50\n",
      "6187/6187 [==============================] - 5s 759us/sample - loss: 0.8123 - acc: 0.8263 - val_loss: 0.7897 - val_acc: 0.8262\n",
      "Epoch 13/50\n",
      "6187/6187 [==============================] - 5s 749us/sample - loss: 0.7660 - acc: 0.8263 - val_loss: 0.7460 - val_acc: 0.8262\n",
      "Epoch 14/50\n",
      "6187/6187 [==============================] - 5s 754us/sample - loss: 0.7249 - acc: 0.8323 - val_loss: 0.7072 - val_acc: 0.8337\n",
      "Epoch 15/50\n",
      "6187/6187 [==============================] - 5s 761us/sample - loss: 0.6882 - acc: 0.8338 - val_loss: 0.6724 - val_acc: 0.8337\n",
      "Epoch 16/50\n",
      "6187/6187 [==============================] - 5s 752us/sample - loss: 0.6552 - acc: 0.8463 - val_loss: 0.6409 - val_acc: 0.8487\n",
      "Epoch 17/50\n",
      "6187/6187 [==============================] - 5s 748us/sample - loss: 0.6253 - acc: 0.8605 - val_loss: 0.6123 - val_acc: 0.8769\n",
      "Epoch 18/50\n",
      "6187/6187 [==============================] - 5s 757us/sample - loss: 0.5979 - acc: 0.8789 - val_loss: 0.5860 - val_acc: 0.8810\n",
      "Epoch 19/50\n",
      "6187/6187 [==============================] - 5s 750us/sample - loss: 0.5727 - acc: 0.9059 - val_loss: 0.5617 - val_acc: 0.9269\n",
      "Epoch 20/50\n",
      "6187/6187 [==============================] - 5s 732us/sample - loss: 0.5494 - acc: 0.9268 - val_loss: 0.5392 - val_acc: 0.9269\n",
      "Epoch 21/50\n",
      "6187/6187 [==============================] - 5s 729us/sample - loss: 0.5277 - acc: 0.9268 - val_loss: 0.5182 - val_acc: 0.9269\n",
      "Epoch 22/50\n",
      "6187/6187 [==============================] - 5s 728us/sample - loss: 0.5074 - acc: 0.9268 - val_loss: 0.4985 - val_acc: 0.9269\n",
      "Epoch 23/50\n",
      "6187/6187 [==============================] - 4s 724us/sample - loss: 0.4884 - acc: 0.9268 - val_loss: 0.4801 - val_acc: 0.9269\n",
      "Epoch 24/50\n",
      "6187/6187 [==============================] - 4s 725us/sample - loss: 0.4705 - acc: 0.9274 - val_loss: 0.4627 - val_acc: 0.9301\n",
      "Epoch 25/50\n",
      "6187/6187 [==============================] - 4s 727us/sample - loss: 0.4536 - acc: 0.9301 - val_loss: 0.4463 - val_acc: 0.9301\n",
      "Epoch 26/50\n",
      "6187/6187 [==============================] - 5s 733us/sample - loss: 0.4377 - acc: 0.9370 - val_loss: 0.4307 - val_acc: 0.9517\n",
      "Epoch 27/50\n",
      "6187/6187 [==============================] - 5s 727us/sample - loss: 0.4226 - acc: 0.9515 - val_loss: 0.4160 - val_acc: 0.9517\n",
      "Epoch 28/50\n",
      "6187/6187 [==============================] - 5s 727us/sample - loss: 0.4083 - acc: 0.9526 - val_loss: 0.4021 - val_acc: 0.9575\n",
      "Epoch 29/50\n",
      "6187/6187 [==============================] - 5s 727us/sample - loss: 0.3948 - acc: 0.9574 - val_loss: 0.3889 - val_acc: 0.9575\n",
      "Epoch 30/50\n",
      "6187/6187 [==============================] - 5s 730us/sample - loss: 0.3819 - acc: 0.9584 - val_loss: 0.3763 - val_acc: 0.9679\n",
      "Epoch 31/50\n",
      "6187/6187 [==============================] - 5s 728us/sample - loss: 0.3697 - acc: 0.9681 - val_loss: 0.3643 - val_acc: 0.9679\n",
      "Epoch 32/50\n",
      "6187/6187 [==============================] - 5s 733us/sample - loss: 0.3580 - acc: 0.9681 - val_loss: 0.3530 - val_acc: 0.9679\n",
      "Epoch 33/50\n",
      "6187/6187 [==============================] - 5s 729us/sample - loss: 0.3470 - acc: 0.9681 - val_loss: 0.3422 - val_acc: 0.9679\n",
      "Epoch 34/50\n",
      "6187/6187 [==============================] - 4s 727us/sample - loss: 0.3364 - acc: 0.9681 - val_loss: 0.3319 - val_acc: 0.9679\n",
      "Epoch 35/50\n",
      "6187/6187 [==============================] - 5s 731us/sample - loss: 0.3264 - acc: 0.9681 - val_loss: 0.3221 - val_acc: 0.9679\n",
      "Epoch 36/50\n",
      "6187/6187 [==============================] - 5s 730us/sample - loss: 0.3169 - acc: 0.9681 - val_loss: 0.3128 - val_acc: 0.9679\n",
      "Epoch 37/50\n",
      "6187/6187 [==============================] - 5s 734us/sample - loss: 0.3078 - acc: 0.9681 - val_loss: 0.3040 - val_acc: 0.9679\n",
      "Epoch 38/50\n",
      "6187/6187 [==============================] - 5s 731us/sample - loss: 0.2992 - acc: 0.9681 - val_loss: 0.2955 - val_acc: 0.9679\n",
      "Epoch 39/50\n",
      "6187/6187 [==============================] - 5s 732us/sample - loss: 0.2910 - acc: 0.9681 - val_loss: 0.2875 - val_acc: 0.9679\n",
      "Epoch 40/50\n",
      "6187/6187 [==============================] - 4s 727us/sample - loss: 0.2831 - acc: 0.9681 - val_loss: 0.2798 - val_acc: 0.9679\n",
      "Epoch 41/50\n",
      "6187/6187 [==============================] - 5s 729us/sample - loss: 0.2756 - acc: 0.9681 - val_loss: 0.2724 - val_acc: 0.9679\n",
      "Epoch 42/50\n",
      "6187/6187 [==============================] - 5s 733us/sample - loss: 0.2684 - acc: 0.9681 - val_loss: 0.2654 - val_acc: 0.9679\n",
      "Epoch 43/50\n",
      "6187/6187 [==============================] - 5s 729us/sample - loss: 0.2615 - acc: 0.9681 - val_loss: 0.2587 - val_acc: 0.9679\n",
      "Epoch 44/50\n",
      "6187/6187 [==============================] - 5s 729us/sample - loss: 0.2550 - acc: 0.9681 - val_loss: 0.2522 - val_acc: 0.9679\n",
      "Epoch 45/50\n",
      "6187/6187 [==============================] - 5s 737us/sample - loss: 0.2487 - acc: 0.9780 - val_loss: 0.2461 - val_acc: 0.9962\n",
      "Epoch 46/50\n",
      "6187/6187 [==============================] - 5s 734us/sample - loss: 0.2426 - acc: 0.9962 - val_loss: 0.2401 - val_acc: 0.9962\n",
      "Epoch 47/50\n",
      "6187/6187 [==============================] - 5s 731us/sample - loss: 0.2368 - acc: 0.9962 - val_loss: 0.2345 - val_acc: 0.9962\n",
      "Epoch 48/50\n",
      "6187/6187 [==============================] - 5s 730us/sample - loss: 0.2313 - acc: 0.9963 - val_loss: 0.2290 - val_acc: 0.9969\n",
      "Epoch 49/50\n",
      "6187/6187 [==============================] - 5s 729us/sample - loss: 0.2259 - acc: 0.9969 - val_loss: 0.2237 - val_acc: 0.9969\n",
      "Epoch 50/50\n",
      "6187/6187 [==============================] - 5s 731us/sample - loss: 0.2208 - acc: 0.9969 - val_loss: 0.2187 - val_acc: 0.9969\n",
      "CPU times: user 18min 12s, sys: 2min 7s, total: 20min 19s\n",
      "Wall time: 3min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "BATCH_SIZE = 200\n",
    "NUM_EPOCHS = 50\n",
    "AUTO_ENC = mf.make_decoder_model(EMBEDDING_MATRIX)\n",
    "AUTO_ENC_HIST = AUTO_ENC.fit(X_train,\n",
    "                             y_train,\n",
    "                             epochs=NUM_EPOCHS,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             validation_data=[X_valid, y_valid],\n",
    "                            )\n",
    "softy = AUTO_ENC.layers[1]\n",
    "np.save(f'{CORPUS_NAME}_softmax', softy.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_summary(AUTO_ENC_HIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x13c5cabe0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAbDklEQVR4nO3dfYxdxXnH8d+zd/2KjY0Ndv0COAlOKGl5SV0whUoJaRLS0OCqaZQqqSwVxVLVVInatKVV1apVqyZSkzTqm+qUtJaaNCASAqUvKaVULU3i8E4AE9YYG2zAa8AGO/jt7n36x17LrnOe2b2zZ8/enf1+JMt7z+ycMzt777NHz5yZMXcXAKAsA1PdAABA/QjuAFAggjsAFIjgDgAFIrgDQIEI7gBQoMHxfJOZ7ZR0UNKIpLa7rzOzJZJulrRG0k5JH3T3/ZPTTABAL3q5c3+Hu1/q7uu6r2+UdLe7r5V0d/c1AKAPTCQtc72kLd2vt0jaMPHmAADqYOOZoWpmz0jaL8kl/Y27bzazA+6+uFtukvafeH1a3U2SNklSS4M/dsbAmb21MGcCrSVOlzhfolpsIPH3MWf2b6JOVDLa/YFWKy4baUdnjOskNDrbObpWqi8S7Uv2YXS6RFnybMG1muy/zG7Ku1a9p6tdP8zRH6uPXvNXXnL3c3o557hy7pKudvc9ZrZM0l1m9uSphe7uZlbZR+6+WdJmSVrUWurr576vl/ZJIyO9fb+UDGh+PApokkX1vBPXmT8/vtaxY9V1En8QUu3zoC8G5s0N69jCBWFZZ/+BoFJmcD92PKte3sWC34ml/tgmfo+pP4Lh6RJ/LAYSfThY/bFrsv9sVvzRT70Hs66V6os+kPo9NmWsPvr3o1/e1es5x5WWcfc93f+HJd0m6XJJe81shSR1/x/u9eIAgMkxZnA3szPMbOGJryW9W9Jjku6QtLH7bRsl3T5ZjQQA9GY8aZnlkm7r5iQHJX3Z3f/NzO6TdIuZ3SBpl6QPTl4zAQC9GDO4u/sOSZdUHH9Z0jt7u5xV5nOTucaM3OrAnMSPVXMOX+1EDj/KrafGBA4fjsuC3KDNnh3XOXIkLLM5c4JKiUHdYBxBSucNo/GCbNHvP5FXT54u6IvUe9MGEjn8xO8kksz8pn6ujL6wIO8vKfyMJH+Hic9j+L5NvV8y8+DROXPbHsr5fSTqec0fD4kZqgBQJII7ABSI4A4ABSK4A0CBxjuJqR7u1QOQicGJeGAlMQKRGBDspCYxBYMxA4viWbV+5GjcjmCw1RacEZ8vYyCpc+j7cWFqckQ0KeqsH5hofMrF4t9VJzHYWvdEkWgwM3fg1lYurzze2f5M1vkGzognt+msRdXHh3ZkXSscpEtNskq8Bzuvv15bG9LtSDyokDkw7p3q+9X0+6/u0cxJGB3NwJ07ABSI4A4ABSK4A0CBms25S8ED/qn8ee+TmCyxkJYOHYrLohxgKl+XmMQUTt4YycsnJi4UFlkrMcEpWp3weDxxJ38ySEOTmFLXSU20Sa3umXG+aHEwSdKR6rGJ7IXIciTGTmqfIJbT9pyJRYlrpSYJ5bQv93fV5CJl3LkDQIEI7gBQIII7ABSo+Zx7Rd4u69nk1HO1mZseRO1IbeTQSeXQouePE4uD5eY1w9Mlnj0P65y7Ji58Mn4W29tNbtaRkcdN9O3xc6qf+x54MpVbTfyuFsbPkSuaa5F8VjxvE5JQaq7F8Eu9ny+jDTaYGAPJXWguel+k+rbm4aDJWAQsB3fuAFAggjsAFIjgDgAFIrgDQIGaHVA1pXc1qu06icG21OSnjMkMqV3kw8lPrcTf1IwB0OSEmcQkq+h3MXAwXjjKUz/vsZoH/TInsuTozK7ui1biPZEaaPfdL8T1zl4aFGT+vDmTjpI7iAUTgVIPD9S9m1GTpnPbE7hzB4ACEdwBoEAEdwAoUKM5d+945aSawQvXhnVee2t1fnLhUwfCOiOPPRWWDZ69JG5fNLkksRBZ5+WXw7KBOYkFzKI68xObPAR50s7hI3Gd5KJi1Tnj9o6d8fly1Z0/j85neQszDf7H/UHBrLBOanOS5NhJcvG6apZoR86En/au5+JrBe+L5IJYGW3InpiVWgAuakfNC5GlFuRLbQiULeNtzZ07ABSI4A4ABSK4A0CBGl84rCon1n5yKPz++UFZ7to87X0ZiyK9+lpclsjldY4mcuF1SuUTM8p2/+4VYZXzPvNQWNZpckG0dr3nG1xzfuXx9s5dcaVE3+775fVh2fK/q+7DVP/VvShba8GCsGwkY0wgS+57Iqde7obbQaDJXtisQdy5A0CBCO4AUCCCOwAUiOAOAAVqfEC1aoJE3YMTdQ8WJRcUS02oqHnQL2xCYgGrVNnA8rMrj6+5eW98scQkq9SuT7UPQOUslpXSqbd9816J2zGwfFl1E1KDtzlSi+SduTCu9/144bi8ZmTsmpWQWsAsXPQs9f5LPXRQ94J3DS44xp07ABSI4A4ABSK4A0CBGs+5N8FWLI8LhzJy7nPmhGWd1zPykzXn5FITXFpnLYorzq5e/GhkyRlhFUssOJVa9Gzk4MG4HTnqzl0mFofLMWd/nOPtPB9v5JElY1Gskb3DvV8ndzGvKEeeeb6U5IYicaWsa9VqrJ93MhcOM7OWmT1kZnd2X7/BzLaa2XYzu9nM4mXSAACN6uXP48clbTvl9aclfc7dL5C0X9INdTYMAJBvXMHdzFZLep+kv+2+NknXSLq1+y1bJG2YjAYCAHo33pz7n0n6TUknHo5dKumAu59YlX63pFVVFc1sk6RNkjRX8xtZcKc99HSt50vl1VtvfXNYNvJ4sGlIgzm+5EJpQZntjDeGGPih6me0Jam9e8+429Vvnv1U9bjKyp+N67TOiMcYBh98Jixr52yCnpLxfmotDjbpltRObEBTZxuSG4xPg4W5Qg0ubJYy5p27mV0nadjdH8i5gLtvdvd17r5uluKBSQBAfcZz536VpPeb2U9LmivpTEmfl7TYzAa7d++rJU3f2zYAKMyYd+7u/tvuvtrd10j6kKT/dPcPS7pH0ge637ZR0u2T1koAQE8mMonptyT9mplt12gO/qZ6mgQAmChzz9stPseZtsSvsHc2dr1G9MEiQX+x63/Dso+df1XP5xuYNy8sS+62hGmj2MHMQv2H3/qAu6/rpQ7LDwBAgQjuAFAggjsAFKjIzToGLrsoLOs89ERcMcifpyardI4cDcuizTrqznd+bM1PhmWD51fOLZMkdfZVT1YZWLUirOPPPBuWtZYsDsvaw/vCsn4wuLL6Z25nLvL12keuDMsWf+2RyuNZi9DlSi5UFbwHMxfz6gv9sDhYw6bxbwsAECG4A0CBCO4AUCCec59GBi9cW3m8/eRQrddJbbrRaF4YfeUj34tXGPmHt8RjO5g4nnMHAEgiuANAkQjuAFAggjsAFKjxSUyVEyFqnmBw7L0/HpbN/tf7ej5fa9GisGzk1Vd7P9+CBfH5Dh0Ky8KB08TkksEVy8OyzoHqth9678Vhnflf/XZY1uhAbPQzZ76XBs8/t/J4e9dzeedbdk5Y1jn0/erjh4/EJ0z9XBmTi2zAEpeqfsgie9A053eVuyBfze+LRtteM+7cAaBABHcAKBDBHQAK1HzOvYGcU05ePSWVV8/Jx6fy6nXLWfhqwb9UL2wlSUpt5NHkBKea30fHz11aedwyc+7+erypySs/f0nl8cVbvpV1rZy+eP4TPxGWrfjMN/PaEcn5XeX+fuuOL022vWbcuQNAgQjuAFAggjsAFKj5nHthcp5zr13NOb7UJtgDc+bWeq26pdrXORo/R273PlxrO1KbrmTn1nv02V3xdX7t/EaagCnEnTsAFIjgDgAFIrgDQIEI7gBQIAZU0ZPUoGQ/yG5fzQtOpQal63bHnvsrj79/1ZWNtQH9hzt3ACgQwR0ACkRwB4ACFZlzj3KQkvT+VT1tIC5JssFZYZm3j/d8PvShPlnsKUfOexrl484dAApEcAeAAhHcAaBARebc685B1p1Xz13cKlTzhry1t28aiH7m2p+bl8LfyZ/ujDcf/+Sa9XntwIw15p27mc01s++Y2SNm9riZ/UH3+BvMbKuZbTezm81s9uQ3FwAwHuNJyxyVdI27XyLpUknXmtl6SZ+W9Dl3v0DSfkk3TF4zAQC9GDO4+6gTm37O6v5zSddIurV7fIukDZPSQgBAz8Y1oGpmLTN7WNKwpLskPS3pgLu3u9+yW9KqoO4mM7vfzO4/rqN1tBkAMIZxDai6+4ikS81ssaTbJF043gu4+2ZJmyXpTFvild9U94Dg7Dj93zl2rOfzpSYxtd4Ub2nTfmpH5fG6B2hbi84My0ZefS2uGPTtwNlL4jqv7A+Lmlwsq24DZy6oPN7ZV/8A8tBfXVF5/JNrar9UaHDp0rCs/fLLzTUEk6anRyHd/YCkeyRdKWmxmZ3447Ba0p6a2wYAyDSep2XO6d6xy8zmSXqXpG0aDfIf6H7bRkm3T1YjAQC9GU9aZoWkLWbW0ugfg1vc/U4ze0LSV8zsjyQ9JOmmSWwnAKAHYwZ3d39U0mUVx3dIuryWVtS8aFNOXj0llSPvPPNsomL1z+UjE23R/zdy4EBYNnjO2WGZj1Q3pLPvpbCOXfimsKy16/mwbOTVV8OyvrBkcfXxRF+kDN30trBs7Q33ZZ2zTuTVy8fyAwBQIII7ABSI4A4ABSK4A0CBpu+qkDVPfMqVGrxtLVxYeXzk4MHJas4PaGcOCIYe3Vbv+fpE+3vbK48ff3e8wujS39sVlq29Ot4NDGgCd+4AUCCCOwAUiOAOAAWatjl3G7CwLHeSUGvRosrjqQk4rcXB5BdJfrh60SlrteI6wcSipD4ZfyjRsxvj30f7M28My+Zp32Q0pyi1fw7w/3DnDgAFIrgDQIEI7gBQoGmbc0/l5HJzeXUvbtU5GuTcE5t/SPXmGltLzgrLOq8dqjze+qFlWdcaeXE4LKt7g5K6Df119QYaaz+8Net8gxfE+fjOc9ULrEXvl0nRB+M05NUnF3fuAFAggjsAFIjgDgAFIrgDQIH6Y0A1MbgTDY6mBuiaHKhJ7YLUmMQA2Mgr+3s+XXt3mXudf+HZe8Oyj55X77Xa23fUe8K6MbmteNy5A0CBCO4AUCCCOwAUqD9y7on8n7ery6JFvqT6JyPlylmILDXBqd8nAvWD393xSFj20fOubrAlwNTizh0ACkRwB4ACEdwBoED9kXNPiJ5z75e8ekpOG8mrj8+dex6oPH7dqh9ruCVAf+LOHQAKRHAHgAIR3AGgQAR3AChQ3w+o9vtuLVm7PvXBLjjTQTRoKjFwCoyFO3cAKBDBHQAKRHAHgAL1fc6932WNCSTy6lk5/Gnsjj33h2XXrVrXYEuAsox5525m55rZPWb2hJk9bmYf7x5fYmZ3mdlQ9/+zJr+5AIDxGE9api3p1939IknrJf2KmV0k6UZJd7v7Wkl3d18DAPrAmMHd3V9w9we7Xx+UtE3SKknXS9rS/bYtkjZMViMBAL3pKeduZmskXSZpq6Tl7v5Ct+hFScuDOpskbZKkuZqf284Zo8S8uiR94/nqTTTes5K8OjAZxv20jJktkPRVSZ9w99dOLXN3l+RV9dx9s7uvc/d1szRnQo0FAIzPuIK7mc3SaGD/krt/rXt4r5mt6JavkDQ8OU0EAPRqPE/LmKSbJG1z98+eUnSHpI3drzdKur3+5gEAcown536VpF+U9F0ze7h77HckfUrSLWZ2g6Rdkj44OU0EAPRqzODu7vdKsqD4nfU2px7ZE4GiBb0Sk44GV64Iy9rPv1B5fHD1qrjO7j1hWY7DG64Iy+Z9fWvP5xuYPTss+95nLwvL3rOy50s1KnrP5A5wp/qpc+xY1jmBXrD8AAAUiOAOAAUiuANAgYpcOCwrry6FufVUDr/9wt6wbHDZOdV19lTn4iVpcM358bV27grLIvPvfDAsO/Izl1cen3NnvJjXs78RTzp6y288FJY1tgVJ5kYoAwsXVh4fOXAg71qJ90zO2A7QK+7cAaBABHcAKBDBHQAKVGTOvfXWN4dlI48/1fP5/PIfiQu/Vb0gliS1h/f1fK2cvHqKt4+HZXP+6TuVx1/8+kVhndUbvhmW9UXGODdvXfOmK53Dh8Oy+Jn63psARLhzB4ACEdwBoEAEdwAoEMEdAApU5IBqatA0Z1Exu++JuE6iHYPLl1Ueb++Nl74ffOOasKy9Y2fiar17+kvVC3296WfjQeKBt701LPNHnozL+nyHqc7hI7WeL3vxOqAm3LkDQIEI7gBQIII7ABSo/3PuGYss1Z3vTE0Eav3ohWFZ+7vVOejBC94Y19m+Y/wNG4ftn18fll3w4W/3fsLHhsKizpU/GpbZvQ+HZSUi546pxp07ABSI4A4ABSK4A0CB+j7nnrPIUu5mHeG1Ejl3f2pnfK1A3Xn139sRb5Lxh3F6P0tqc+fpnFdP/Y5zJPup5s24gSrcuQNAgQjuAFAggjsAFIjgDgAF6v8B1QGrPO7tzB13EpOfcs7ZOVrvglMpX929tfL4z62+orE2YOIYOEUTuHMHgAIR3AGgQAR3AChQX+TcU4ssRZNBBtecH9Zp79wVlg3Mnt37tZYuja/18sth2bH3XV55fPY/fyes88yf/ERY9nOrw6IsrSVnVR4feWV/WGdg/vywrPP66xNu04QlJqmlxluyzpeScy2gRty5A0CBCO4AUCCCOwAUqC9y7t6Jt5keXPumyuPtoafDOq1Fi8KykVdfDcuifHwqr955+9vCsii3PvTn8QYaa3/1m2FZjiivLqVz65FUXn1g3ry43uHDPV8rS925bnLnmKbGvHM3sy+a2bCZPXbKsSVmdpeZDXX/jyMIAKBx40nL/L2ka087dqOku919raS7u68BAH1izODu7v8t6ZXTDl8vaUv36y2SNtTcLgDABOTm3Je7+wvdr1+UtDz6RjPbJGmTJM1V/Iw0AKA+Ex5QdXc3s3BE1N03S9osSWfaksrvG5gVNyMcOF1/SVhn5NuPhGVZk5jOOTus0/6vB8Oy/b90ZeXxtb/6rbDO4Q3xImDzvl69cFhqElhq0LS1cGF1nYMH4zo1D9DWLdUXOQt2pc6XmuCU3NkpqsfgLWqU+yjkXjNbIUnd/4fraxIAYKJyg/sdkjZ2v94o6fZ6mgMAqMN4HoX8R0nfkvQWM9ttZjdI+pSkd5nZkKSf6r4GAPSJMXPu7v4LQdE762pEaqf41sU/XHk8mVfPnEwT5Vfb+14K6zz1hR8Py9780ercul1xcVgnyqunpHLJg8uXhWXtvb1n00b2JyaBzZkbljW1qUndG2Gkz5d5LXLraADLDwBAgQjuAFAggjsAFIjgDgAF6otVIW1wVlg28ui23s+XmKhkicHbaPDsqkfjOrr4vrCotWBB5fGRrY+GdVJ9kZwYE0gOmgaTaVoLzgirpCY4NTVoOu0xiQkN4M4dAApEcAeAAhHcAaBAfZFzT+WSw4WbEos2pXZbSvnic/dWHv+lc6/OOt/IoUOVx5OLW2Xk1VN9kczjBmWpvDpqQG4dDeDOHQAKRHAHgAIR3AGgQH2Rc0+JF27KW7TpC89W59WlOLeeuwFEtDFIaqG0rOfcyeECOA137gBQIII7ABSI4A4ABSK4A0CB+mNANTEJZ2BWdRNTg5LXPbE/LPvoeYkJSUE7BubPD6v40aNhWdTGuhcHS8kZDM7dUSl34LkvsJgXCsOdOwAUiOAOAAUiuANAgfoj554Q5a2vf+LlsM7tFy3Nu1i0kNah7/dcR5IGV62sPN7e83xYp7VoUViWsyBaTq47d9ONvs+rp5BbR2G4cweAAhHcAaBABHcAKFDf59w/sK16g+dbf3hZWKf258hTefWVK8KyKLded14dAE7HnTsAFIjgDgAFIrgDQIEI7gBQoL4YUP3Kc/8bln3o3KuCkniQs+7Ft1Laz78QFwaLUTFoCmCycecOAAUiuANAgQjuAFCgRnPub774dX3jG4/8wPH3rLwyUWsaL+jEYlQApsiE7tzN7Foz+56ZbTezG+tqFABgYrKDu5m1JP2lpPdKukjSL5jZRXU1DACQbyJ37pdL2u7uO9z9mKSvSLq+nmYBACZiIjn3VZKeO+X1bklXnP5NZrZJ0qbuy6OtFUOP/eCphibQjGnrbEkvTXUj+gR9cRJ9cRJ9cdJbeq0w6QOq7r5Z0mZJMrP73X3dZF9zOqAvTqIvTqIvTqIvTjKz+3utM5G0zB5J557yenX3GABgik0kuN8naa2ZvcHMZkv6kKQ76mkWAGAistMy7t42s49J+oaklqQvuvvjY1TbnHu9AtEXJ9EXJ9EXJ9EXJ/XcF+buk9EQAMAUYvkBACgQwR0ACtRIcJ/pyxSY2RfNbNjMHjvl2BIzu8vMhrr/nzWVbWyCmZ1rZveY2RNm9riZfbx7fCb2xVwz+46ZPdLtiz/oHn+DmW3tflZu7j6sMCOYWcvMHjKzO7uvZ2RfmNlOM/uumT184hHInM/IpAd3limQJP29pGtPO3ajpLvdfa2ku7uvS9eW9OvufpGk9ZJ+pftemIl9cVTSNe5+iaRLJV1rZuslfVrS59z9Akn7Jd0whW1s2sclbTvl9Uzui3e4+6WnPOff82ekiTv3Gb9Mgbv/t6RXTjt8vaQt3a+3SNrQaKOmgLu/4O4Pdr8+qNEP8irNzL5wdz/UfTmr+88lXSPp1u7xGdEXkmRmqyW9T9Lfdl+bZmhfBHr+jDQR3KuWKVjVwHX73XJ3P7FH34uSlk9lY5pmZmskXSZpq2ZoX3TTEA9LGpZ0l6SnJR1w93b3W2bSZ+XPJP2mTq7xvVQzty9c0r+b2QPd5VukjM9IX+yhOtO5u5vZjHkm1cwWSPqqpE+4+2ujN2mjZlJfuPuIpEvNbLGk2yRdOMVNmhJmdp2kYXd/wMzePtXt6QNXu/seM1sm6S4ze/LUwvF+Rpq4c2eZgmp7zWyFJHX/H57i9jTCzGZpNLB/yd2/1j08I/viBHc/IOkeSVdKWmxmJ266Zspn5SpJ7zeznRpN214j6fOamX0hd9/T/X9Yo3/0L1fGZ6SJ4M4yBdXukLSx+/VGSbdPYVsa0c2j3iRpm7t/9pSimdgX53Tv2GVm8yS9S6NjEPdI+kD322ZEX7j7b7v7andfo9H48J/u/mHNwL4wszPMbOGJryW9W9JjyviMNDJD1cx+WqM5tRPLFPzxpF+0j5jZP0p6u0aXMN0r6fclfV3SLZLOk7RL0gfd/fRB16KY2dWS/kfSd3Uyt/o7Gs27z7S+uFijA2Mtjd5k3eLuf2hmb9To3esSSQ9J+oi7H526ljarm5b5pLtfNxP7ovsz39Z9OSjpy+7+x2a2VD1+Rlh+AAAKxAxVACgQwR0ACkRwB4ACEdwBoEAEdwAoEMEdAApEcAeAAv0fVuTFtCHdxhcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense\n",
    "from tensorflow import keras \n",
    "\n",
    "emb_test = Embedding(CATAGORICAL_DIM,\n",
    "                     EMBEDDING_DIM,\n",
    "                     weights = [EMBEDDING_MATRIX],\n",
    "                     trainable=False)\n",
    "soft_test = Dense(CATAGORICAL_DIM,\n",
    "                  weights=softy.get_weights(),\n",
    "                  trainable=False,\n",
    "                  activation='softmax')\n",
    "test_model = keras.models.Sequential()\n",
    "test_model.add(emb_test)\n",
    "test_model.add(soft_test)\n",
    "game = np.array([np.linspace(0, CATAGORICAL_DIM-1,CATAGORICAL_DIM),])\n",
    "plt.pcolormesh((test_model.predict(game))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent neural network model\n",
    "Now that we know our embedded representation is not super lossy, we can move on to train a predictive. Our goal will be to forecast the next play given the current and previous plays. We will do this using two LSTM layers, sandwiched between our autoencoding layers, which will work in the embedded representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell resets \n",
    "import tensorflow as tf\n",
    "from tensorflow.core.protobuf import rewriter_config_pb2\n",
    "from tensorflow.keras.backend import set_session\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "\n",
    "config_proto = tf.ConfigProto()\n",
    "off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "session = tf.Session(config=config_proto)\n",
    "set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 189 ms, sys: 209 ms, total: 398 ms\n",
      "Wall time: 396 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "BATCH_SIZE = 400\n",
    "NUM_STEPS = len(CORPUS_IND[0])-1\n",
    "NUM_EPOCHS = 50\n",
    "SOFTMAX_WEIGHTS = np.load(f'{CORPUS_NAME}_softmax.npy',\n",
    "                          allow_pickle=True)\n",
    "\n",
    "X_train, X_valid, _ = dp.tvt_split(CORPUS_IND)\n",
    "y_train = one_hot(X_train, CATAGORICAL_DIM)\n",
    "y_valid = one_hot(X_valid, CATAGORICAL_DIM)\n",
    "\n",
    "# the length must be divisible by the batch size\n",
    "train_len = len(X_train)//BATCH_SIZE*BATCH_SIZE\n",
    "valid_len = len(X_valid)//BATCH_SIZE*BATCH_SIZE\n",
    "\n",
    "# offset the targets from the inputs by one play\n",
    "X_train = X_train[:train_len,:-1]\n",
    "X_valid = X_valid[:valid_len,:-1]\n",
    "y_train = y_train[:train_len,1:]\n",
    "y_valid = y_valid[:valid_len,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved softmax weights. This might not be necessary\n",
    "SOFTMAX_WEIGHTS = np.load(f'{CORPUS_NAME}_softmax.npy',\n",
    "                          allow_pickle=True)\n",
    "\n",
    "RNN_MODEL = mf.make_rnn_training_model(embedding_matrix=EMBEDDING_MATRIX,\n",
    "                            softmax_weights=SOFTMAX_WEIGHTS,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            num_steps=NUM_STEPS,\n",
    "                            train_softmax=False,\n",
    "                            train_embedding=False,)\n",
    "\n",
    "RNN_HIST = RNN_MODEL.fit(X_train,\n",
    "                         y_train,\n",
    "                         epochs=NUM_EPOCHS,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         validation_data=[X_valid, y_valid],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_training_summary(RNN_HIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 3.8213 - acc: 0.0512 - val_loss: 3.6487 - val_acc: 0.0517\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 16s 3ms/sample - loss: 3.4797 - acc: 0.2898 - val_loss: 3.2965 - val_acc: 0.4121\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 16s 3ms/sample - loss: 3.1452 - acc: 0.4150 - val_loss: 2.9775 - val_acc: 0.4145\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 16s 3ms/sample - loss: 2.8281 - acc: 0.4181 - val_loss: 2.6646 - val_acc: 0.4478\n",
      "Epoch 5/100\n",
      "6000/6000 [==============================] - 16s 3ms/sample - loss: 2.5228 - acc: 0.4547 - val_loss: 2.3823 - val_acc: 0.4533\n",
      "Epoch 6/100\n",
      "6000/6000 [==============================] - 16s 3ms/sample - loss: 2.2852 - acc: 0.4567 - val_loss: 2.2061 - val_acc: 0.4557\n",
      "Epoch 7/100\n",
      "6000/6000 [==============================] - 16s 3ms/sample - loss: 2.1518 - acc: 0.4584 - val_loss: 2.1118 - val_acc: 0.4579\n",
      "Epoch 8/100\n",
      "6000/6000 [==============================] - 16s 3ms/sample - loss: 2.0796 - acc: 0.4602 - val_loss: 2.0586 - val_acc: 0.4584\n",
      "Epoch 9/100\n",
      "6000/6000 [==============================] - 16s 3ms/sample - loss: 2.0363 - acc: 0.4607 - val_loss: 2.0247 - val_acc: 0.4594\n",
      "Epoch 10/100\n",
      "6000/6000 [==============================] - 16s 3ms/sample - loss: 2.0073 - acc: 0.4623 - val_loss: 2.0004 - val_acc: 0.4606\n",
      "Epoch 11/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.9856 - acc: 0.4627 - val_loss: 1.9813 - val_acc: 0.4607\n",
      "Epoch 12/100\n",
      "6000/6000 [==============================] - 16s 3ms/sample - loss: 1.9682 - acc: 0.4627 - val_loss: 1.9656 - val_acc: 0.4607\n",
      "Epoch 13/100\n",
      "6000/6000 [==============================] - 16s 3ms/sample - loss: 1.9533 - acc: 0.4628 - val_loss: 1.9513 - val_acc: 0.4609\n",
      "Epoch 14/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.9394 - acc: 0.4630 - val_loss: 1.9378 - val_acc: 0.4609\n",
      "Epoch 15/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.9261 - acc: 0.4630 - val_loss: 1.9247 - val_acc: 0.4609\n",
      "Epoch 16/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.9128 - acc: 0.4630 - val_loss: 1.9109 - val_acc: 0.4610\n",
      "Epoch 17/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.8985 - acc: 0.4630 - val_loss: 1.8958 - val_acc: 0.4610\n",
      "Epoch 18/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.8826 - acc: 0.4630 - val_loss: 1.8790 - val_acc: 0.4610\n",
      "Epoch 19/100\n",
      "6000/6000 [==============================] - 18s 3ms/sample - loss: 1.8650 - acc: 0.4630 - val_loss: 1.8606 - val_acc: 0.4610\n",
      "Epoch 20/100\n",
      "6000/6000 [==============================] - 18s 3ms/sample - loss: 1.8460 - acc: 0.4630 - val_loss: 1.8410 - val_acc: 0.4610\n",
      "Epoch 21/100\n",
      "6000/6000 [==============================] - 22s 4ms/sample - loss: 1.8261 - acc: 0.4634 - val_loss: 1.8205 - val_acc: 0.4619\n",
      "Epoch 22/100\n",
      "6000/6000 [==============================] - 22s 4ms/sample - loss: 1.8052 - acc: 0.4757 - val_loss: 1.7992 - val_acc: 0.4851\n",
      "Epoch 23/100\n",
      "6000/6000 [==============================] - 21s 3ms/sample - loss: 1.7838 - acc: 0.4963 - val_loss: 1.7779 - val_acc: 0.5052\n",
      "Epoch 24/100\n",
      "6000/6000 [==============================] - 22s 4ms/sample - loss: 1.7626 - acc: 0.5169 - val_loss: 1.7566 - val_acc: 0.5244\n",
      "Epoch 25/100\n",
      "6000/6000 [==============================] - 18s 3ms/sample - loss: 1.7415 - acc: 0.5310 - val_loss: 1.7355 - val_acc: 0.5311\n",
      "Epoch 26/100\n",
      "6000/6000 [==============================] - 19s 3ms/sample - loss: 1.7202 - acc: 0.5336 - val_loss: 1.7140 - val_acc: 0.5317\n",
      "Epoch 27/100\n",
      "6000/6000 [==============================] - 21s 3ms/sample - loss: 1.6990 - acc: 0.5349 - val_loss: 1.6930 - val_acc: 0.5340\n",
      "Epoch 28/100\n",
      "6000/6000 [==============================] - 20s 3ms/sample - loss: 1.6781 - acc: 0.5359 - val_loss: 1.6722 - val_acc: 0.5343\n",
      "Epoch 29/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.6578 - acc: 0.5371 - val_loss: 1.6524 - val_acc: 0.5363\n",
      "Epoch 30/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.6387 - acc: 0.5404 - val_loss: 1.6339 - val_acc: 0.5413\n",
      "Epoch 31/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.6208 - acc: 0.5453 - val_loss: 1.6168 - val_acc: 0.5461\n",
      "Epoch 32/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.6044 - acc: 0.5497 - val_loss: 1.6011 - val_acc: 0.5494\n",
      "Epoch 33/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.5893 - acc: 0.5536 - val_loss: 1.5866 - val_acc: 0.5534\n",
      "Epoch 34/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.5755 - acc: 0.5560 - val_loss: 1.5734 - val_acc: 0.5548\n",
      "Epoch 35/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.5629 - acc: 0.5571 - val_loss: 1.5614 - val_acc: 0.5558\n",
      "Epoch 36/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.5515 - acc: 0.5590 - val_loss: 1.5507 - val_acc: 0.5583\n",
      "Epoch 37/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.5414 - acc: 0.5606 - val_loss: 1.5413 - val_acc: 0.5594\n",
      "Epoch 38/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.5325 - acc: 0.5614 - val_loss: 1.5329 - val_acc: 0.5600\n",
      "Epoch 39/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.5247 - acc: 0.5620 - val_loss: 1.5256 - val_acc: 0.5605\n",
      "Epoch 40/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.5177 - acc: 0.5624 - val_loss: 1.5191 - val_acc: 0.5607\n",
      "Epoch 41/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.5116 - acc: 0.5627 - val_loss: 1.5133 - val_acc: 0.5610\n",
      "Epoch 42/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.5060 - acc: 0.5629 - val_loss: 1.5080 - val_acc: 0.5612\n",
      "Epoch 43/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.5010 - acc: 0.5631 - val_loss: 1.5033 - val_acc: 0.5614\n",
      "Epoch 44/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4965 - acc: 0.5632 - val_loss: 1.4990 - val_acc: 0.5615\n",
      "Epoch 45/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4924 - acc: 0.5633 - val_loss: 1.4950 - val_acc: 0.5616\n",
      "Epoch 46/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4886 - acc: 0.5634 - val_loss: 1.4914 - val_acc: 0.5617\n",
      "Epoch 47/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4851 - acc: 0.5635 - val_loss: 1.4880 - val_acc: 0.5617\n",
      "Epoch 48/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4819 - acc: 0.5635 - val_loss: 1.4849 - val_acc: 0.5618\n",
      "Epoch 49/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4788 - acc: 0.5636 - val_loss: 1.4819 - val_acc: 0.5618\n",
      "Epoch 50/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4759 - acc: 0.5636 - val_loss: 1.4790 - val_acc: 0.5618\n",
      "Epoch 51/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4731 - acc: 0.5637 - val_loss: 1.4764 - val_acc: 0.5621\n",
      "Epoch 52/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4705 - acc: 0.5638 - val_loss: 1.4738 - val_acc: 0.5621\n",
      "Epoch 53/100\n",
      "6000/6000 [==============================] - 18s 3ms/sample - loss: 1.4680 - acc: 0.5640 - val_loss: 1.4714 - val_acc: 0.5623\n",
      "Epoch 54/100\n",
      "6000/6000 [==============================] - 18s 3ms/sample - loss: 1.4656 - acc: 0.5642 - val_loss: 1.4690 - val_acc: 0.5627\n",
      "Epoch 55/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4633 - acc: 0.5645 - val_loss: 1.4668 - val_acc: 0.5628\n",
      "Epoch 56/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4611 - acc: 0.5647 - val_loss: 1.4646 - val_acc: 0.5631\n",
      "Epoch 57/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4590 - acc: 0.5649 - val_loss: 1.4626 - val_acc: 0.5633\n",
      "Epoch 58/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4570 - acc: 0.5651 - val_loss: 1.4606 - val_acc: 0.5635\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4551 - acc: 0.5654 - val_loss: 1.4587 - val_acc: 0.5637\n",
      "Epoch 60/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4532 - acc: 0.5656 - val_loss: 1.4569 - val_acc: 0.5640\n",
      "Epoch 61/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4515 - acc: 0.5658 - val_loss: 1.4552 - val_acc: 0.5641\n",
      "Epoch 62/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4498 - acc: 0.5661 - val_loss: 1.4535 - val_acc: 0.5646\n",
      "Epoch 63/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4481 - acc: 0.5663 - val_loss: 1.4519 - val_acc: 0.5647\n",
      "Epoch 64/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4466 - acc: 0.5665 - val_loss: 1.4504 - val_acc: 0.5652\n",
      "Epoch 65/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4451 - acc: 0.5684 - val_loss: 1.4490 - val_acc: 0.5673\n",
      "Epoch 66/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4437 - acc: 0.5689 - val_loss: 1.4476 - val_acc: 0.5677\n",
      "Epoch 67/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4424 - acc: 0.5693 - val_loss: 1.4463 - val_acc: 0.5677\n",
      "Epoch 68/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4411 - acc: 0.5695 - val_loss: 1.4450 - val_acc: 0.5680\n",
      "Epoch 69/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4399 - acc: 0.5697 - val_loss: 1.4438 - val_acc: 0.5683\n",
      "Epoch 70/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4387 - acc: 0.5700 - val_loss: 1.4426 - val_acc: 0.5685\n",
      "Epoch 71/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4375 - acc: 0.5702 - val_loss: 1.4415 - val_acc: 0.5687\n",
      "Epoch 72/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4364 - acc: 0.5705 - val_loss: 1.4404 - val_acc: 0.5689\n",
      "Epoch 73/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4353 - acc: 0.5707 - val_loss: 1.4394 - val_acc: 0.5691\n",
      "Epoch 74/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4343 - acc: 0.5710 - val_loss: 1.4383 - val_acc: 0.5693\n",
      "Epoch 75/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4333 - acc: 0.5712 - val_loss: 1.4374 - val_acc: 0.5697\n",
      "Epoch 76/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4324 - acc: 0.5714 - val_loss: 1.4365 - val_acc: 0.5698\n",
      "Epoch 77/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4315 - acc: 0.5717 - val_loss: 1.4356 - val_acc: 0.5700\n",
      "Epoch 78/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4306 - acc: 0.5719 - val_loss: 1.4348 - val_acc: 0.5702\n",
      "Epoch 79/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4298 - acc: 0.5721 - val_loss: 1.4339 - val_acc: 0.5704\n",
      "Epoch 80/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4289 - acc: 0.5723 - val_loss: 1.4331 - val_acc: 0.5706\n",
      "Epoch 81/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4281 - acc: 0.5724 - val_loss: 1.4323 - val_acc: 0.5706\n",
      "Epoch 82/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4273 - acc: 0.5726 - val_loss: 1.4315 - val_acc: 0.5709\n",
      "Epoch 83/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4266 - acc: 0.5727 - val_loss: 1.4307 - val_acc: 0.5710\n",
      "Epoch 84/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4258 - acc: 0.5729 - val_loss: 1.4300 - val_acc: 0.5712\n",
      "Epoch 85/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4251 - acc: 0.5730 - val_loss: 1.4293 - val_acc: 0.5715\n",
      "Epoch 86/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4244 - acc: 0.5732 - val_loss: 1.4286 - val_acc: 0.5715\n",
      "Epoch 87/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4237 - acc: 0.5733 - val_loss: 1.4279 - val_acc: 0.5717\n",
      "Epoch 88/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4230 - acc: 0.5734 - val_loss: 1.4272 - val_acc: 0.5718\n",
      "Epoch 89/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4223 - acc: 0.5736 - val_loss: 1.4265 - val_acc: 0.5720\n",
      "Epoch 90/100\n",
      "6000/6000 [==============================] - 18s 3ms/sample - loss: 1.4216 - acc: 0.5737 - val_loss: 1.4258 - val_acc: 0.5721\n",
      "Epoch 91/100\n",
      "6000/6000 [==============================] - 16s 3ms/sample - loss: 1.4209 - acc: 0.5738 - val_loss: 1.4252 - val_acc: 0.5721\n",
      "Epoch 92/100\n",
      "6000/6000 [==============================] - 16s 3ms/sample - loss: 1.4203 - acc: 0.5739 - val_loss: 1.4245 - val_acc: 0.5722\n",
      "Epoch 93/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4196 - acc: 0.5740 - val_loss: 1.4239 - val_acc: 0.5723\n",
      "Epoch 94/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4190 - acc: 0.5741 - val_loss: 1.4233 - val_acc: 0.5725\n",
      "Epoch 95/100\n",
      "6000/6000 [==============================] - 16s 3ms/sample - loss: 1.4184 - acc: 0.5742 - val_loss: 1.4228 - val_acc: 0.5725\n",
      "Epoch 96/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4178 - acc: 0.5743 - val_loss: 1.4221 - val_acc: 0.5726\n",
      "Epoch 97/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4172 - acc: 0.5744 - val_loss: 1.4215 - val_acc: 0.5727\n",
      "Epoch 98/100\n",
      "6000/6000 [==============================] - 16s 3ms/sample - loss: 1.4166 - acc: 0.5745 - val_loss: 1.4209 - val_acc: 0.5727\n",
      "Epoch 99/100\n",
      "6000/6000 [==============================] - 17s 3ms/sample - loss: 1.4160 - acc: 0.5746 - val_loss: 1.4204 - val_acc: 0.5729\n",
      "Epoch 100/100\n",
      "6000/6000 [==============================] - 16s 3ms/sample - loss: 1.4154 - acc: 0.5747 - val_loss: 1.4198 - val_acc: 0.5730\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 100\n",
    "RNN_MODEL_SOFT_FIT = mf.make_rnn_training_model(embedding_matrix=EMBEDDING_MATRIX,\n",
    "                            softmax_weights=SOFTMAX_WEIGHTS,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            num_steps=NUM_STEPS,\n",
    "                            train_embedding=False,\n",
    "                            train_softmax=True)\n",
    "\n",
    "RNN_S_HIST = RNN_MODEL_SOFT_FIT.fit(X_train,\n",
    "                         y_train,\n",
    "                         epochs=NUM_EPOCHS,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         validation_data=[X_valid, y_valid],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_summary(RNN_S_HIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN evaluation\n",
    "Roughly 35% of the plays are actually just padding at the end of the game. The RNN probably gets those right, and the Markov chain definitely does. We should consider the accuracy excluding these predictions when assessing the quality of the model. This can be done by recalculating the accuracy assuming all of the pad plays were correctly predicted. The result is a lower bound on the accuracy of the RNN with respect to in-game plays. We find an adjusted **validation accuracy of .3303 for the RNN model**, which drastically outpreforms the **.1902 validation accuracy of the baseline model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN adjusted validation accuracy = 0.3303\n",
      "1st order markov chain adjusted validation accuracy = 0.1924\n"
     ]
    }
   ],
   "source": [
    "num_games, num_plays = CORPUS_IND.shape\n",
    "pad_percent = WV.vocab[str({'Type':'Pad'})].count/(num_games*num_plays)\n",
    "valid_percent = 1-pad_percent\n",
    "RNN_val_acc = .5780 #best for a longer training session()\n",
    "MC1_val_acc = .4911 #see baseline_models.py\n",
    "RNN_adj_acc = np.round((RNN_val_acc-pad_percent)/valid_percent,4)\n",
    "MC1_adj_acc = np.round((MC1_val_acc-pad_percent)/valid_percent,4)\n",
    "print(f'RNN adjusted validation accuracy = {RNN_adj_acc}')\n",
    "print(f'1st order markov chain adjusted validation accuracy = {MC1_adj_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the models\n",
    "We'll have to save the trained model so we can use it on the website. \n",
    "\n",
    "```python\n",
    "model_json = model.to_json()\n",
    "```\n",
    "creates a json of the model architecture in ```model_json```\n",
    " \n",
    "```python \n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "```\n",
    "writes the json to the file ```model.json```\n",
    "\n",
    "```python\n",
    "model.save_weights(\"model.h5\")\n",
    "```\n",
    "saves the weights of ```model``` in the file ```model.h5```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = RNN_MODEL_SOFT_FIT.to_json()\n",
    "with open(f\"RNN_MODEL_SOFT_FIT.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "RNN_MODEL_SOFT_FIT.save_weights(f\"RNN_MODEL_SOFT_FIT.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the models\n",
    "The model architecture and weights can be reloaded form these files:\n",
    "```python\n",
    "with open(\"model.json\", \"rb\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "```\n",
    "loads the architecture in json form the file, \n",
    "\n",
    "```python\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "```\n",
    "creates the model (requires ```from tensorflow.keras.models import model_from_json```),\n",
    "\n",
    "```python\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "```\n",
    "loads the weights.\n",
    "\n",
    "In reality, we will want a new model with a different input batch size, ```(1, None)```, for (```num_games, time_step```) for our predictions. This is done with the function ```make_rnn_predicting_model(hdf5_file, cat_dim, emb_dim)```, which takes a path to a weights file, and the dimensionality of the categorical and embedded spaces as arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "with open(\"RNN_MODEL_SOFT_FIT.json\", \"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "loaded_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model._layers[0].batch_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dim, emb_dim = EMBEDDING_MATRIX.shape\n",
    "hdf5_file = f\"RNN_MODEL_SOFT_FIT.h5\"\n",
    "RNN_PRED = mf.make_rnn_predicting_model(hdf5_file, cat_dim, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "def load_model_json(filename):\n",
    "    with open(filename, \"r\") as json_file:\n",
    "        loaded_model_json = json_file.read()\n",
    "    return model_from_json(loaded_model_json)\n",
    "\n",
    "def save_model_json(model, filename):\n",
    "    model_json = model.to_json()\n",
    "    with open(filename, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "        \n",
    "RNN_MODEL_SOFT_FIT.save_weights(f\"RNN_MODEL_SOFT_FIT.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'RNN_PRED.json'\n",
    "save_model_json(RNN_PRED, filename)\n",
    "RNN_PRED.save_weights('RNN_PRED.h5')\n",
    "\n",
    "test_mod = load_model_json(filename)\n",
    "test_mod.load_weights(\"RNN_PRED.h5\")\n",
    "test_mod.predict([0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GAME = 3\n",
    "START = 0\n",
    "STOP = 10\n",
    "INPUT_PLAYS = CORPUS_IND[GAME,START:STOP]\n",
    "ACTUAL_NEXT = CORPUS_IND[GAME, (START+1):(STOP+1)]\n",
    "RNN_PRED.reset_states()\n",
    "PRED = RNN_PRED.predict(INPUT_PLAYS)[:,0]\n",
    "print(RNN_PRED.predict(INPUT_PLAYS).shape)\n",
    "MAX_PROB_NEXT = np.argmax(PRED, axis=1)[:]\n",
    "ACTUAL_PROB_NEXT = [np.round(PRED[i, actual_ind],2) for i, actual_ind in enumerate(ACTUAL_NEXT)]\n",
    "PRED.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(INPUT_PLAYS)\n",
    "print(ACTUAL_NEXT)\n",
    "print(MAX_PROB_NEXT)\n",
    "print(ACTUAL_PROB_NEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, play, in enumerate(WV.index2word):\n",
    "    print(i, play)\n",
    "WV.index2word[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.utils.vis_utils as vsutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RNN_PRED.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/Users/tiwariku/environments/shot2vec/bin/python3 -m pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsutil.model_to_dot(RNN_PRED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10,10,1000)\n",
    "y = np.sign(x)*np.log(np.abs(x+np.sign(x)))\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from tensorflow.keras.utils import to_categorical as one_hot\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def wv_index_corpus(corpus, wv):\n",
    "    \"\"\"\n",
    "    in  corpus, a corpus with plays in string-serialized format\n",
    "            and \n",
    "        wv, the assocated wordvector object\n",
    "        \n",
    "    out: corpus_index, the corpus in index format\n",
    "    \"\"\"\n",
    "    corpus_index = np.zeros((len(corpus), len(corpus[0])), dtype=np.int32)\n",
    "    for gi, game in enumerate(corpus):\n",
    "        for pi, play in enumerate(game):\n",
    "            corpus_index[gi, pi] =  wv.vocab[play].index\n",
    "    return corpus_index\n",
    "\n",
    "def make_embedding(name, \n",
    "                   corpus, \n",
    "                   embedding_size, \n",
    "                   window=5, \n",
    "                   min_count=1, \n",
    "                   workers=4):\n",
    "    \"\"\"\n",
    "    Trains a gensim word2vec model on the corpus, \n",
    "        saves the indexed corpus and wordvectors\n",
    "    in:\n",
    "        name, the filename associated with this embedding scheme\n",
    "        corpus, the corpus to train on (in serialized play-dict format)\n",
    "        embedding_size, the size of the embedded representation\n",
    "        window=5, the max skip-gram for the word2vec\n",
    "        min_count=1, min count for word2vec\n",
    "        workers=4, number of workers to use by gensim\n",
    "    \"\"\"\n",
    "    model = Word2Vec(corpus,\n",
    "                     size=embedding_size,\n",
    "                     window=window,\n",
    "                     min_count=min_count,\n",
    "                     workers=workers)\n",
    "    model.wv.save(f'{name}.wv')\n",
    "    corpus_index = wv_index_corpus(corpus, model.wv)\n",
    "    np.save(name, corpus_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "def make_decoder_model(embedding_matrix):\n",
    "    \"\"\"\n",
    "    makes a compiled variational autoencoder model with \n",
    "    un-trainable embedding layer whose weights are specified by...\n",
    "    in:\n",
    "        embedding matrix\n",
    "    \"\"\"\n",
    "    cat_dim, emb_dim = embedding_matrix.shape\n",
    "    embed = Embedding(cat_dim,\n",
    "                  emb_dim,\n",
    "                  #batch_input_shape = (batch_size, num_steps),\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=False)\n",
    "    old_softy = TimeDistributed(Dense(cat_dim, \n",
    "                                      activation='softmax'))\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(embed)\n",
    "    model.add(old_softy)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def fit_softmax(data, num_epochs, batch_size, embedding_matrix):\n",
    "    \"\"\"\n",
    "    Unused, this should probably just be in the main script\n",
    "    \"\"\"\n",
    "    X_train, X_valid, y_train, y_valid = data\n",
    "    auto_enc = make_decoder_model(EMBEDDING_MATRIX)\n",
    "    auto_enc_hist = auto_enc.fit(X_train,\n",
    "                             y_train,\n",
    "                             epochs=num_epochs,\n",
    "                             batch_size=batch_size,\n",
    "                             validation_data=[X_valid, y_valid],\n",
    "                            ) \n",
    "    return auto_enc, auto_enc_hist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "def make_rnn_training_model(embedding_matrix,\n",
    "                            softmax_weights,\n",
    "                            batch_size,\n",
    "                            num_steps,\n",
    "                            train_embedding=True,\n",
    "                            train_softmax=True,):\n",
    "    \"\"\"\n",
    "    returns a compiled RNN model with two lstm layers of \n",
    "    size 'embeddeding_size'\n",
    "    \"\"\"\n",
    "    cat_dim, emb_dim = embedding_matrix.shape\n",
    "    layers = []\n",
    "    embed = Embedding(cat_dim,\n",
    "                  emb_dim,\n",
    "                  batch_input_shape = (batch_size, num_steps),\n",
    "                  weights=[embedding_matrix],\n",
    "                  trainable=train_embedding)\n",
    "    lstm1 = LSTM(emb_dim,\n",
    "                 #batch_input_shape = (batch_size, num_steps, embedded_dim),\n",
    "                 stateful=True,\n",
    "                 return_sequences=True,\n",
    "                )\n",
    "    lstm2 = LSTM(emb_dim,\n",
    "                 #batch_input_shape = (batch_size, num_steps, embedded_dim),\n",
    "                 stateful=True,\n",
    "                 return_sequences=True,\n",
    "                )\n",
    "    old_softy = TimeDistributed(Dense(cat_dim, \n",
    "                                      weights=softmax_weights,\n",
    "                                      trainable=train_softmax,\n",
    "                                      activation='softmax'))\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(embed)\n",
    "    model.add(lstm1)\n",
    "    model.add(lstm2)\n",
    "    model.add(old_softy)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model \n",
    "\n",
    "def make_rnn_predicting_model(hdf5_file, cat_dim, emb_dim):\n",
    "    \"\"\"\n",
    "    returns a compiled RNN model with two lstm layers of \n",
    "    size 'embeddeding_size'\n",
    "    \"\"\"\n",
    "    #cat_dim, emb_dim = embedding_matrix.shape\n",
    "    layers = []\n",
    "    embed = Embedding(cat_dim,\n",
    "                  emb_dim,\n",
    "                  batch_input_shape = (1, None),\n",
    "                  #weights=[embedding_matrix],\n",
    "                  #trainable=False\n",
    "                     )\n",
    "    lstm1 = LSTM(emb_dim,\n",
    "                 #batch_input_shape = (batch_size, num_steps, embedded_dim),\n",
    "                 stateful=True,\n",
    "                 return_sequences=True,\n",
    "                )\n",
    "    lstm2 = LSTM(emb_dim,\n",
    "                 #batch_input_shape = (batch_size, num_steps, embedded_dim),\n",
    "                 stateful=True,\n",
    "                 return_sequences=True,\n",
    "                )\n",
    "    old_softy = TimeDistributed(Dense(cat_dim, \n",
    "                                      #weights=softmax_weights,\n",
    "                                      #trainable=train_softmax,\n",
    "                                      activation='softmax'))\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(embed)\n",
    "    model.add(lstm1)\n",
    "    model.add(lstm2)\n",
    "    model.add(old_softy)\n",
    "    model.load_weights(hdf5_file)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_training_summary(history):\n",
    "    \"\"\"\n",
    "    Plots the validation and training accuracy and loss\n",
    "    of a keras history\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(2,1,1)\n",
    "    ax.semilogy(history.history['loss'], '.', label='Train')\n",
    "    ax.semilogy(history.history['val_loss'],'.',  label='Val')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax = fig.add_subplot(2,1,2)\n",
    "    ax.semilogy(1-np.array(history.history['acc']), '.', label='Train')\n",
    "    ax.semilogy(1-np.array(history.history['val_acc']),'.',  label='Val')\n",
    "    ax.set_ylabel('1-Accuracy')\n",
    "    ax.set_xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(\"RNN_MODEL_SOFT_FIT.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
